{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "Q7iWhXnQp-tD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "uYVClZZpp3na"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Transformations\n",
        "We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise."
      ],
      "metadata": {
        "id": "Z3_o6mHFqOMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Phase transformations\n",
        "train_transforms = transforms.Compose([\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
        "                                      ])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       ])"
      ],
      "metadata": {
        "id": "UdbS4VpbqW8g"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Creating Train/Test Split"
      ],
      "metadata": {
        "id": "RryTucN0qcXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"
      ],
      "metadata": {
        "id": "wJPX9Z2CqjAS"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataloader Arguments & Test/Train Dataloaders"
      ],
      "metadata": {
        "id": "5e6xD4lOqp9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUHnWoAKq7_1",
        "outputId": "bb13a266-e8b3-43b1-99e7-9eb924a8e859"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "Let's start with the model we first saw"
      ],
      "metadata": {
        "id": "ESBVKEHuriNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_value = 0.03\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1), # Input - 28x28x1, Output - 28x28x16, RF - 3x3\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.Conv2d(16, 16, 3, padding=1), # Input - 28x28x16, Output - 28x28x16, RF - 5x5\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            #nn.Dropout(dropout_value),\n",
        "            nn.MaxPool2d(2, 2) # Input - 28x28x16, Output - 14x14x16\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, 3, padding=1), # Input - 14x14x16, Output - 14x14x16, RF - 10x10\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.Conv2d(16, 16, 3, padding=1), # Input - 14x14x16, Output - 14x14x16, RF - 12x12\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            #nn.Dropout(dropout_value),\n",
        "            nn.MaxPool2d(2, 2) # Input - 14x14x16, Output - 7x7x16\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, 3, padding=1), # Input - 7x7x16, Output - 7x7x16, RF - 24x24\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), # Input - 7x7x16, Output - 7x7x32, RF - 26x26\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(dropout_value),\n",
        "            nn.Conv2d(32, 10, 3, padding=1), # Input - 7x7x32, Output - 7x7x10, RF - 28x28\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(10),\n",
        "            nn.AvgPool2d(7, 7) # Input - 7x7x10, Output - 1x1x10\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "6Gr6k-1kzIuy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Params"
      ],
      "metadata": {
        "id": "Tg4oGwISsKWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBCwrtMMsfdH",
        "outputId": "b0c5e7c2-83fd-4104-f765-97c4c42d6c4a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 28, 28]             160\n",
            "              ReLU-2           [-1, 16, 28, 28]               0\n",
            "       BatchNorm2d-3           [-1, 16, 28, 28]              32\n",
            "           Dropout-4           [-1, 16, 28, 28]               0\n",
            "            Conv2d-5           [-1, 16, 28, 28]           2,320\n",
            "              ReLU-6           [-1, 16, 28, 28]               0\n",
            "       BatchNorm2d-7           [-1, 16, 28, 28]              32\n",
            "         MaxPool2d-8           [-1, 16, 14, 14]               0\n",
            "            Conv2d-9           [-1, 16, 14, 14]           2,320\n",
            "             ReLU-10           [-1, 16, 14, 14]               0\n",
            "      BatchNorm2d-11           [-1, 16, 14, 14]              32\n",
            "          Dropout-12           [-1, 16, 14, 14]               0\n",
            "           Conv2d-13           [-1, 16, 14, 14]           2,320\n",
            "             ReLU-14           [-1, 16, 14, 14]               0\n",
            "      BatchNorm2d-15           [-1, 16, 14, 14]              32\n",
            "        MaxPool2d-16             [-1, 16, 7, 7]               0\n",
            "           Conv2d-17             [-1, 16, 7, 7]           2,320\n",
            "             ReLU-18             [-1, 16, 7, 7]               0\n",
            "      BatchNorm2d-19             [-1, 16, 7, 7]              32\n",
            "          Dropout-20             [-1, 16, 7, 7]               0\n",
            "           Conv2d-21             [-1, 32, 7, 7]           4,640\n",
            "             ReLU-22             [-1, 32, 7, 7]               0\n",
            "      BatchNorm2d-23             [-1, 32, 7, 7]              64\n",
            "          Dropout-24             [-1, 32, 7, 7]               0\n",
            "           Conv2d-25             [-1, 10, 7, 7]           2,890\n",
            "             ReLU-26             [-1, 10, 7, 7]               0\n",
            "      BatchNorm2d-27             [-1, 10, 7, 7]              20\n",
            "        AvgPool2d-28             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 17,214\n",
            "Trainable params: 17,214\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.95\n",
            "Params size (MB): 0.07\n",
            "Estimated Total Size (MB): 1.02\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing\n",
        "\n",
        "\n",
        "Let's write train and test functions"
      ],
      "metadata": {
        "id": "BM3s70W_sge6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "     "
      ],
      "metadata": {
        "id": "B5myBpmKsqGa"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's Train and test our model"
      ],
      "metadata": {
        "id": "WZazI11fs1_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "EPOCHS = 20\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eAaxR3Ps8Rv",
        "outputId": "b0be7a2c-07ed-4ef3-f2a0-674a8159c655"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.15864364802837372 Batch_id=468 Accuracy=93.39: 100%|██████████| 469/469 [00:22<00:00, 21.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0813, Accuracy: 9814/10000 (98.14%)\n",
            "\n",
            "EPOCH: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.12182533740997314 Batch_id=468 Accuracy=98.37: 100%|██████████| 469/469 [00:20<00:00, 22.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0472, Accuracy: 9899/10000 (98.99%)\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.037838950753211975 Batch_id=468 Accuracy=98.73: 100%|██████████| 469/469 [00:21<00:00, 21.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0387, Accuracy: 9914/10000 (99.14%)\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.042664870619773865 Batch_id=468 Accuracy=98.88: 100%|██████████| 469/469 [00:21<00:00, 21.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0306, Accuracy: 9928/10000 (99.28%)\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.016000309959053993 Batch_id=468 Accuracy=98.99: 100%|██████████| 469/469 [00:24<00:00, 19.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0320, Accuracy: 9907/10000 (99.07%)\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.06371597200632095 Batch_id=468 Accuracy=99.12: 100%|██████████| 469/469 [00:21<00:00, 21.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0289, Accuracy: 9918/10000 (99.18%)\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.05555548146367073 Batch_id=468 Accuracy=99.15: 100%|██████████| 469/469 [00:21<00:00, 22.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0271, Accuracy: 9917/10000 (99.17%)\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.01830575428903103 Batch_id=468 Accuracy=99.24: 100%|██████████| 469/469 [00:21<00:00, 22.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0328, Accuracy: 9919/10000 (99.19%)\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.029013989493250847 Batch_id=468 Accuracy=99.23: 100%|██████████| 469/469 [00:22<00:00, 21.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0245, Accuracy: 9931/10000 (99.31%)\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.008937672711908817 Batch_id=468 Accuracy=99.33: 100%|██████████| 469/469 [00:22<00:00, 21.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0229, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.02367362193763256 Batch_id=468 Accuracy=99.46: 100%|██████████| 469/469 [00:21<00:00, 22.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0279, Accuracy: 9914/10000 (99.14%)\n",
            "\n",
            "EPOCH: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.012812796980142593 Batch_id=468 Accuracy=99.41: 100%|██████████| 469/469 [00:20<00:00, 22.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0218, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.0503528006374836 Batch_id=468 Accuracy=99.48: 100%|██████████| 469/469 [00:21<00:00, 21.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0247, Accuracy: 9926/10000 (99.26%)\n",
            "\n",
            "EPOCH: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.0052206325344741344 Batch_id=468 Accuracy=99.46: 100%|██████████| 469/469 [00:22<00:00, 20.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0233, Accuracy: 9931/10000 (99.31%)\n",
            "\n",
            "EPOCH: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.02741345949470997 Batch_id=468 Accuracy=99.55: 100%|██████████| 469/469 [00:22<00:00, 20.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0221, Accuracy: 9932/10000 (99.32%)\n",
            "\n",
            "EPOCH: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.02204611711204052 Batch_id=468 Accuracy=99.56: 100%|██████████| 469/469 [00:22<00:00, 20.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0236, Accuracy: 9936/10000 (99.36%)\n",
            "\n",
            "EPOCH: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.012274441309273243 Batch_id=468 Accuracy=99.56: 100%|██████████| 469/469 [00:21<00:00, 21.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0215, Accuracy: 9929/10000 (99.29%)\n",
            "\n",
            "EPOCH: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.04882970452308655 Batch_id=468 Accuracy=99.55: 100%|██████████| 469/469 [00:20<00:00, 22.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0189, Accuracy: 9943/10000 (99.43%)\n",
            "\n",
            "EPOCH: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.010073154233396053 Batch_id=468 Accuracy=99.60: 100%|██████████| 469/469 [00:21<00:00, 21.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0194, Accuracy: 9931/10000 (99.31%)\n",
            "\n",
            "EPOCH: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.005589574109762907 Batch_id=468 Accuracy=99.60: 100%|██████████| 469/469 [00:21<00:00, 21.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0224, Accuracy: 9928/10000 (99.28%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}